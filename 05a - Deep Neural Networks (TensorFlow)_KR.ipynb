{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow를 이용한 딥러닝\n",
    "\n",
    "기존의 머신러닝은 통계 방법을 사용하여 특징(feature)과 라벨(label) 사이의 관계를 결정하는 데에 의존하면서 예측 모델을 만드는 데 매우 효과적일 수 있습니다. 하지만 엄청난 데이터 가용성의 증가는 그것을 처리하는 데 필요한 컴퓨팅 기술의 발전과 결합되어 인간의 뇌가 인공 신경망이라고 불리는 구조에서 정보를 처리하는 방식을 모방하여 새로운 머신러닝 기술의 출현으로 이어졌습니다.\n",
    "\n",
    "TensorFlow는 깊은 신경망(deep neural networks, DNN)을 포함한 머신러닝 모델을 만들기 위한 프레임워크입니다. 이 예에서는 TensorFlow를 사용하여 부리(culmen)의 길이와 깊이, 날개(FlipperLength) 및 체질량(BodyMass)을 기준으로 펭귄의 종으로 분류하는 간단한 신경망을 생성합니다.\n",
    "\n",
    "> **인용**: 이 연습에 사용된 펭귄 데이터셋은 [Dr. Kristen Gorman](https://www.uaf.edu/cfos/people/faculty/detail/kristen-gorman.php) 과 [Long Term Ecological Research Network](https://lternet.edu/)의 멤버인 [Palmer Station, Antarctica LTER](https://pal.lternet.edu/)이 수집하여 사용할 수 있게 만든 데이터의 서브셋이다.\n",
    "\n",
    "## 데이터셋 살펴보기\n",
    "\n",
    "PyTorch를 사용하기 전에 모델을 만들기 위해 Palmer Islands 펭귄 데이터셋으로부터 필요한 데이터를 불러오겠습니다. 이 데이터셋에는 3가지 종류의 펭귄이 관찰되어 있습니다.\n",
    "\n",
    "> **참조**: 실제로는 딥러닝 모델 없이도 기존의 머신러닝 기술을 사용하여 펭귄 분류 문제를 쉽게 해결할 수 있습니다. 하지만 이 노트북에서 신경 네트워크의 원리를 설명하는 데이터셋은 유용하고 이해하기 쉽습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CulmenLength</th>\n",
       "      <th>CulmenDepth</th>\n",
       "      <th>FlipperLength</th>\n",
       "      <th>BodyMass</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>36.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>19.5</td>\n",
       "      <td>34.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>50.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>23.0</td>\n",
       "      <td>57.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>49.1</td>\n",
       "      <td>14.5</td>\n",
       "      <td>21.2</td>\n",
       "      <td>46.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>47.0</td>\n",
       "      <td>17.3</td>\n",
       "      <td>18.5</td>\n",
       "      <td>37.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>43.5</td>\n",
       "      <td>18.1</td>\n",
       "      <td>20.2</td>\n",
       "      <td>34.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>50.5</td>\n",
       "      <td>18.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>34.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>51.3</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.8</td>\n",
       "      <td>37.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>51.3</td>\n",
       "      <td>19.2</td>\n",
       "      <td>19.3</td>\n",
       "      <td>36.50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>47.3</td>\n",
       "      <td>15.3</td>\n",
       "      <td>22.2</td>\n",
       "      <td>52.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>37.5</td>\n",
       "      <td>18.9</td>\n",
       "      <td>17.9</td>\n",
       "      <td>29.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CulmenLength  CulmenDepth  FlipperLength  BodyMass  Species\n",
       "148          36.0         17.8           19.5     34.50        0\n",
       "153          50.0         16.3           23.0     57.00        1\n",
       "232          49.1         14.5           21.2     46.25        1\n",
       "288          47.0         17.3           18.5     37.00        2\n",
       "340          43.5         18.1           20.2     34.00        2\n",
       "302          50.5         18.4           20.0     34.00        2\n",
       "285          51.3         19.9           19.8     37.00        2\n",
       "278          51.3         19.2           19.3     36.50        2\n",
       "182          47.3         15.3           22.2     52.50        1\n",
       "47           37.5         18.9           17.9     29.75        0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the training dataset (excluding rows with null values)\n",
    "penguins = pd.read_csv('data/penguins.csv').dropna()\n",
    "\n",
    "# Deep Learning models work best when features are on similar scales\n",
    "# In a real solution, we'd implement some custom normalization for each feature, but to keep things simple\n",
    "# we'll just rescale the FlipperLength and BodyMass so they're on a similar scale to the bill measurements\n",
    "penguins['FlipperLength'] = penguins['FlipperLength']/10\n",
    "penguins['BodyMass'] = penguins['BodyMass']/100\n",
    "\n",
    "# The dataset is too small to be useful for deep learning\n",
    "# So we'll oversample it to increase its size\n",
    "for i in range(1,3):\n",
    "    penguins = penguins.append(penguins)\n",
    "\n",
    "# Display a random sample of 10 observations\n",
    "sample = penguins.sample(10)\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Species** 열은 모델이 예측할 레이블입니다. 각 라벨 값은 0, 1 또는 2로 인코딩된 펭귄 종의 클래스를 나타냅니다. 다음 코드는 이러한 클래스 라벨에 해당하는 실제 종을 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CulmenLength' 'CulmenDepth' 'FlipperLength' 'BodyMass' 'Species'] SpeciesName\n",
      "[ 50.2 18.8 20.2 38.0 2 ] Chinstrap\n",
      "[ 36.3 19.5 19.0 38.0 0 ] Adelie\n",
      "[ 50.7 15.0 22.3 55.5 1 ] Gentoo\n",
      "[ 36.0 17.8 19.5 34.5 0 ] Adelie\n",
      "[ 45.3 13.8 20.8 42.0 1 ] Gentoo\n",
      "[ 48.7 14.1 21.0 44.5 1 ] Gentoo\n",
      "[ 40.5 17.9 18.7 32.0 0 ] Adelie\n",
      "[ 37.7 16.0 18.3 30.75 0 ] Adelie\n",
      "[ 42.5 20.7 19.7 45.0 0 ] Adelie\n",
      "[ 36.8 18.5 19.3 35.0 0 ] Adelie\n"
     ]
    }
   ],
   "source": [
    "penguin_classes = ['Adelie', 'Gentoo', 'Chinstrap']\n",
    "print(sample.columns[0:5].values, 'SpeciesName')\n",
    "for index, row in penguins.sample(10).iterrows():\n",
    "    print('[',row[0], row[1], row[2],row[3], int(row[4]), ']',penguin_classes[int(row[-1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "흔히 지도학습 문제에서 볼 수 있듯이, 데이터셋을 일련의 레코드로 분할하여 모델을 학습하고, 학습된 모델을 검증할 수 있는 작은 데이터셋으로 분할합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: 957, Test Set: 411 \n",
      "\n",
      "Sample of features and labels:\n",
      "[51.1 16.5 22.5 52.5] 1 (Gentoo)\n",
      "[50.7 19.7 20.3 40.5] 2 (Chinstrap)\n",
      "[49.5 16.2 22.9 58. ] 1 (Gentoo)\n",
      "[39.3 20.6 19.  36.5] 0 (Adelie)\n",
      "[42.5 20.7 19.7 45. ] 0 (Adelie)\n",
      "[50.  15.3 22.  55.5] 1 (Gentoo)\n",
      "[50.2  18.7  19.8  37.75] 2 (Chinstrap)\n",
      "[50.7 19.7 20.3 40.5] 2 (Chinstrap)\n",
      "[49.1  14.5  21.2  46.25] 1 (Gentoo)\n",
      "[43.2 16.6 18.7 29. ] 2 (Chinstrap)\n",
      "[38.8  17.6  19.1  32.75] 0 (Adelie)\n",
      "[37.8 17.1 18.6 33. ] 0 (Adelie)\n",
      "[45.8 14.2 21.9 47. ] 1 (Gentoo)\n",
      "[43.8 13.9 20.8 43. ] 1 (Gentoo)\n",
      "[36.  17.1 18.7 37. ] 0 (Adelie)\n",
      "[43.3 13.4 20.9 44. ] 1 (Gentoo)\n",
      "[36.  18.5 18.6 31. ] 0 (Adelie)\n",
      "[41.1  19.   18.2  34.25] 0 (Adelie)\n",
      "[33.1 16.1 17.8 29. ] 0 (Adelie)\n",
      "[40.9 13.7 21.4 46.5] 1 (Gentoo)\n",
      "[45.2 17.8 19.8 39.5] 2 (Chinstrap)\n",
      "[48.4 14.6 21.3 58.5] 1 (Gentoo)\n",
      "[43.6 13.9 21.7 49. ] 1 (Gentoo)\n",
      "[38.5  17.9  19.   33.25] 0 (Adelie)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = ['CulmenLength','CulmenDepth','FlipperLength','BodyMass']\n",
    "label = 'Species'\n",
    "   \n",
    "# Split data 70%-30% into training set and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(penguins[features].values,\n",
    "                                                    penguins[label].values,\n",
    "                                                    test_size=0.30,\n",
    "                                                    random_state=0)\n",
    "\n",
    "print ('Training Set: %d, Test Set: %d \\n' % (len(x_train), len(x_test)))\n",
    "print(\"Sample of features and labels:\")\n",
    "\n",
    "# Take a look at the first 25 training features and corresponding labels\n",
    "for n in range(0,24):\n",
    "    print(x_train[n], y_train[n], '(' + penguin_classes[y_train[n]] + ')')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*특징(features)*은 각 펭귄 관찰에 대한 측정치이며 *라벨(label)* 은 관찰이 나타내는 펭귄의 종(Adelie, Gentoo 또는 Chinstrap)을 나타내는 숫자 값입니다.\n",
    "\n",
    "## TensorFlow 라이브러리 설치 및 임포트\n",
    "\n",
    "TensorFlow를 사용하여 펭귄 분류 모델을 만들 예정이기 때문에, 사용하려는 라이브러리를 설치하고 임포트 하기 위해 아래 2개의 셀을 실행해야 합니다.\n",
    "\n",
    "> **참조** *Keras* 는 기본 TensorFlow API를 통한 abstraction layer입니다. 대부분의 일반적인 시스템 학습 시나리오에서 Keras를 사용하여 코드를 단순화할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n",
      "Keras version: 2.4.0\n",
      "TensorFlow version: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "# Set random seed for reproducability\n",
    "tensorflow.random.set_seed(0)\n",
    "\n",
    "print(\"Libraries imported.\")\n",
    "print('Keras version:',keras.__version__)\n",
    "print('TensorFlow version:',tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow에서 데이터 준비하기\n",
    "\n",
    "우리는 이미 데이터를 로드하여 학습 및 검증 데이터셋으로 분할했습니다.그러나 데이터가 TensorFlow에서 올바르게 작동하도록 추가 데이터 준비해야 합니다. 특히, 피쳐의 데이터 타입을 32비트 부동 소수점으로 설정하고 레이블이 숫자 값이 아닌 범주형 클래스를 나타내도록 지정해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready...\n"
     ]
    }
   ],
   "source": [
    "# Set data types for float features\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Set data types for categorical labels\n",
    "y_train = utils.to_categorical(y_train)\n",
    "y_test = utils.to_categorical(y_test)\n",
    "print('Ready...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 신경망 정의하기\n",
    "\n",
    "이제 우리는 우리의 신경망을 정의할 준비가 되었다. 이 경우에는 3개의 완전 연결층(fully-connected layers)으로 구성된 네트워크를 구축하겠습니다:\n",
    "* 각 형상에 대해 입력 값(이 경우 4개의 펭귄 측정값)을 수신하고 *ReLU*  활성화 함수를 적용하는 입력 층입니다.\n",
    "* 10개의 입력을 받고, *ReLU* 활성화 함수를 적용하는 은닉 층입니다.\n",
    "* *Softmax* 활성화 함수를 사용하여 각 펭귄 종에 대한 출력을 생성하는 출력 층입니다(이 출력 층은 3가지 펭귄 종 각각에 대하여 분류 확률을 나타냅니다). Softmax 함수는 전체 합계가 1인 확률 값을 가진 벡터를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 193\n",
      "Trainable params: 193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define a classifier network\n",
    "hl = 10 # Number of hidden layer nodes\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(hl, input_dim=len(features), activation='relu'))\n",
    "model.add(Dense(hl, input_dim=hl, activation='relu'))\n",
    "model.add(Dense(len(penguin_classes), input_dim=hl, activation='softmax'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습하기\n",
    "\n",
    "모델을 교육하기 위해서는 반복적으로 네트워크에서 학습을 통해 계산된 값을 공급하고, 손실 함수를 사용하여 손실을 계산하고, Optimizer를 사용하여 가중치와 바이어스 값 조정하고, 보류한 테스트 데이터셋을 사용하여 모델을 검증해야 합니다.\n",
    "\n",
    "이를 위해 Adam Optimizer를 범주형 교차 엔트로피 손실 함수에 50번 에포크 넘게 반복 적용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "96/96 [==============================] - 3s 18ms/step - loss: 31.1438 - accuracy: 0.1969 - val_loss: 11.2900 - val_accuracy: 0.2165\n",
      "Epoch 2/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 7.8160 - accuracy: 0.2031 - val_loss: 1.5626 - val_accuracy: 0.1752\n",
      "Epoch 3/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 1.3587 - accuracy: 0.1955 - val_loss: 1.1591 - val_accuracy: 0.3139\n",
      "Epoch 4/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 1.1261 - accuracy: 0.3163 - val_loss: 1.0832 - val_accuracy: 0.4453\n",
      "Epoch 5/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 1.0618 - accuracy: 0.4275 - val_loss: 1.0545 - val_accuracy: 0.4574\n",
      "Epoch 6/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 1.0403 - accuracy: 0.4957 - val_loss: 1.0425 - val_accuracy: 0.4842\n",
      "Epoch 7/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 1.0202 - accuracy: 0.5395 - val_loss: 1.0315 - val_accuracy: 0.5547\n",
      "Epoch 8/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 1.0188 - accuracy: 0.6026 - val_loss: 1.0189 - val_accuracy: 0.6156\n",
      "Epoch 9/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.9881 - accuracy: 0.6290 - val_loss: 1.0050 - val_accuracy: 0.6521\n",
      "Epoch 10/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.9704 - accuracy: 0.6842 - val_loss: 0.9911 - val_accuracy: 0.6618\n",
      "Epoch 11/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.9606 - accuracy: 0.7131 - val_loss: 0.9781 - val_accuracy: 0.6813\n",
      "Epoch 12/50\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.9433 - accuracy: 0.69 - 1s 6ms/step - loss: 0.9432 - accuracy: 0.6961 - val_loss: 0.8758 - val_accuracy: 0.6350\n",
      "Epoch 13/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.8152 - accuracy: 0.7154 - val_loss: 0.7991 - val_accuracy: 0.7129\n",
      "Epoch 14/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.7517 - accuracy: 0.7371 - val_loss: 0.7381 - val_accuracy: 0.7202\n",
      "Epoch 15/50\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.6827 - accuracy: 0.7734 - val_loss: 0.6803 - val_accuracy: 0.7421\n",
      "Epoch 16/50\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.6317 - accuracy: 0.7835 - val_loss: 0.6292 - val_accuracy: 0.7470\n",
      "Epoch 17/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.5733 - accuracy: 0.8021 - val_loss: 0.5870 - val_accuracy: 0.7567\n",
      "Epoch 18/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.5491 - accuracy: 0.8091 - val_loss: 0.5660 - val_accuracy: 0.7786\n",
      "Epoch 19/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.4957 - accuracy: 0.8289 - val_loss: 0.5272 - val_accuracy: 0.7786\n",
      "Epoch 20/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.4809 - accuracy: 0.8125 - val_loss: 0.4847 - val_accuracy: 0.7713\n",
      "Epoch 21/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.4636 - accuracy: 0.8100 - val_loss: 0.4676 - val_accuracy: 0.7640\n",
      "Epoch 22/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.4153 - accuracy: 0.8241 - val_loss: 0.4518 - val_accuracy: 0.7689\n",
      "Epoch 23/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.4052 - accuracy: 0.8290 - val_loss: 0.4383 - val_accuracy: 0.8054\n",
      "Epoch 24/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.3758 - accuracy: 0.8653 - val_loss: 0.3915 - val_accuracy: 0.8224\n",
      "Epoch 25/50\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.3634 - accuracy: 0.8757 - val_loss: 0.3924 - val_accuracy: 0.8808\n",
      "Epoch 26/50\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.3604 - accuracy: 0.8988 - val_loss: 0.3522 - val_accuracy: 0.8710\n",
      "Epoch 27/50\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.3050 - accuracy: 0.9232 - val_loss: 0.3363 - val_accuracy: 0.8759\n",
      "Epoch 28/50\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.3036 - accuracy: 0.9135 - val_loss: 0.3216 - val_accuracy: 0.9002\n",
      "Epoch 29/50\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.2905 - accuracy: 0.9252 - val_loss: 0.3075 - val_accuracy: 0.8929\n",
      "Epoch 30/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.2803 - accuracy: 0.9294 - val_loss: 0.2890 - val_accuracy: 0.9075\n",
      "Epoch 31/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.2530 - accuracy: 0.9427 - val_loss: 0.2871 - val_accuracy: 0.8662\n",
      "Epoch 32/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.2504 - accuracy: 0.9327 - val_loss: 0.2752 - val_accuracy: 0.8832\n",
      "Epoch 33/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.2302 - accuracy: 0.9393 - val_loss: 0.2491 - val_accuracy: 0.9148\n",
      "Epoch 34/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.2198 - accuracy: 0.9539 - val_loss: 0.2343 - val_accuracy: 0.9367\n",
      "Epoch 35/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1995 - accuracy: 0.9608 - val_loss: 0.2233 - val_accuracy: 0.9489\n",
      "Epoch 36/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1979 - accuracy: 0.9606 - val_loss: 0.2061 - val_accuracy: 0.9635\n",
      "Epoch 37/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1893 - accuracy: 0.9592 - val_loss: 0.2004 - val_accuracy: 0.9562\n",
      "Epoch 38/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1616 - accuracy: 0.9649 - val_loss: 0.1851 - val_accuracy: 0.9732\n",
      "Epoch 39/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1668 - accuracy: 0.9670 - val_loss: 0.1749 - val_accuracy: 0.9757\n",
      "Epoch 40/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1452 - accuracy: 0.9637 - val_loss: 0.1627 - val_accuracy: 0.9684\n",
      "Epoch 41/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1418 - accuracy: 0.9782 - val_loss: 0.1555 - val_accuracy: 0.9708\n",
      "Epoch 42/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1430 - accuracy: 0.9680 - val_loss: 0.1717 - val_accuracy: 0.9465\n",
      "Epoch 43/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1283 - accuracy: 0.9764 - val_loss: 0.1403 - val_accuracy: 0.9805\n",
      "Epoch 44/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1157 - accuracy: 0.9787 - val_loss: 0.1313 - val_accuracy: 0.9781\n",
      "Epoch 45/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1181 - accuracy: 0.9741 - val_loss: 0.1224 - val_accuracy: 0.9805\n",
      "Epoch 46/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1056 - accuracy: 0.9804 - val_loss: 0.1165 - val_accuracy: 0.9830\n",
      "Epoch 47/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1058 - accuracy: 0.9794 - val_loss: 0.1173 - val_accuracy: 0.9732\n",
      "Epoch 48/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.0921 - accuracy: 0.9819 - val_loss: 0.1118 - val_accuracy: 0.9805\n",
      "Epoch 49/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.0933 - accuracy: 0.9839 - val_loss: 0.1019 - val_accuracy: 0.9830\n",
      "Epoch 50/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.0883 - accuracy: 0.9854 - val_loss: 0.1046 - val_accuracy: 0.9708\n"
     ]
    }
   ],
   "source": [
    "#hyper-parameters for optimizer\n",
    "learning_rate = 0.001\n",
    "opt = optimizers.Adam(lr=learning_rate)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model over 50 epochs using 10-observation batches and using the test holdout dataset for validation\n",
    "num_epochs = 50\n",
    "history = model.fit(x_train, y_train, epochs=num_epochs, batch_size=10, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 프로세스가 실행되는 동안 어떤 일이 일어나고 있는지 알아보겠습니다:\n",
    "\n",
    "1. 각 *epoch*에서 전체 학습 데이터셋이 네트워크를 통해 전달됩니다. 각 관측치에 대해 4개의 피쳐와 입력 층에 4개의 노드가 있으므로 각 관측치에 대한 피쳐는 4개의 값의 벡터로 해당 계층에 전달됩니다. 하지만 효율성을 위해 피쳐 벡터는 배치로 그룹화되므로 여러 기능 벡터의 매트릭스가 매번 제공됩니다. \n",
    "2. 피쳐 값의 매트릭스는 초기 가중치와 바이어스 값을 사용하여 가중 합계를 수행하는 함수로 처리됩니다. 그 다음 이 함수의 결과는 다음 레이어의 노드에 전달되는 값을 제한하기 위해 입력 층에 대한 활성화 함수에 의해 처리됩니다.\n",
    "3. 가중 합과 활성화 함수는 각 레이어에서 반복됩니다. 함수는 개별 스칼라 값이 아닌 벡터와 매트릭스에서 작동합니다. 다시 말해, 정방향 계산은 본질적으로 중첩된 선형 대수 함수의 연속입니다. 이것이 바로 데이터사이언티스트들이 그래픽 처리 장치(GPU)가 있는 컴퓨터를 선호하는 이유입니다. GPU는 매트릭스와 벡터 계산에 최적화되어 있기 때문입니다.\n",
    "4. 네트워크의 최종 레이어에서 출력 벡터에는 각 클래스에 대한 확률 값이 포함됩니다(이 경우 클래스 0, 1, 2). 이 벡터는 네트워크에서 계산된 값이 실제 값과 얼마나 떨어져 있는지를 결정하기 위해 *손실 함수* 에 의해 처리됩니다. 예를 들어, Gentoo 펭귄(클래스 1) 관측치에 대한 출력이 \\[0.3, 0.4, 0.3\\]라고 가정합니다. 올바른 예측은 \\[0.0, 1.0, 0.0\\]이므로 예측 값과 실제 값 사이의 차이는 \\[0.3, 0.6, 0.3\\]입니다. 이 차이는 각 배치에 대해 집계되고 실행 애그리게이트로 유지되어 해당 에포크의 학습 데이터에 의해 발생한 전체 오류 수준(*손실*)을 계산합니다.\n",
    "5. 각 에포크가 끝날 때마다 검증 데이터가 네트워크를 통과하며, 데이터의 손실과 정확도가 계산됩니다. 이렇게 하면 학습하지 않은 데이터를 사용하여 모델의 성능을 비교하고, 새로운 데이터에 맞게 일반화된 것인지, 아니면 학습 데이터에 *과적합* 된 것인지 판단할 수 있기 때문에 매우 중요합니다. \n",
    "6. 모든 데이터가 네트워크를 통해 전달되면 *학습* 데이터에 대한 손실 함수의 출력이 opimizer로 전달됩니다. 최적화 도구에서 손실 처리 방법에 대한 정확한 세부 정보는 사용 중인 특정 최적화 알고리즘에 따라 다르지만 기본적으로 입력 층에서 손실 함수에 이르는 전체 네트워크를 하나의 큰 중첩(*복합(composite)*) 기능으로 생각할 수 있습니다. optimizer는 네트워크에서 사용된 각 가중치와 바이어스 값과 관련하여 *부분 도함수*를 계산하기 위해 일부 미적분을 적용합니다. 내부 함수와 외부 함수의 미분에서 합성 함수(composite function)의 미분을 결정할 수 있도록 *체인 룰(chain rule)* 이라는 기능으로 인해 중첩 함수에 대해이를 효율적으로 수행 할 수 있습니다. 여러분은 여기서 수학의 세부사항에 대해 걱정할 필요가 없지만, 최종 결과는 편미분값(partial derivatives)이 우리에게 각 가중치와 바이어스 값에 대한 손실 함수의 기울기(또는 *gradient*)에 대해 말해준다는 것입니다. 다시 말해서, 우리는 손실을 줄이기 위해서 가중치와 바이어스 값을 증가시킬지 감소시킬지 결정할 수 있습니다.\n",
    "7. 가중치와 바이어스를 어느 방향으로 조정할 지를 결정한 optimizer는 *learning rate* 를 사용하여 어느 정도까지 조정할 지를 결정하고, *역전파(backpropagation)* 라는 프로세스를 통해 네트워크를 통해 역방향으로 연산하여 각 레이어의 가중치와 바이어스에 새로운 값을 할당한다.\n",
    "8. 이제 다음 에포크는 이전 에포크에서 수정된 가중치와 바이어스로 시작하는 전체 학습, 검증 및 역전파 과정을 반복한다. 이는 희망컨대 더 적은 손실값을 유도할 것이다.\n",
    "9. 이러한 에포크는 50번 반복된다.\n",
    "\n",
    "## 학습 및 검증 손실 리뷰\n",
    "\n",
    "학습이 완료되면 학습 및 모델 검증 과정에서 기록한 손실 메트릭스를 검토할 수 있습니다. 저희는 두 가지를 정말 찾고 있습니다:\n",
    "* 손실은 각 에포크에 따라 감소해야 하며, 모델이 올바른 라벨을 예측하기 위한 올바른 가중치와 편향을 학습하고 있음을 보여준다.\n",
    "* 훈련 손실과 검증 손실도 유사한 추세를 따라야 하며, 이는 모델이 훈련 데이터에 과적합되지 않음을 보여준다.\\\n",
    "\n",
    "손실 메트릭을 플롯팅하고 다음을 살펴보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.10462380200624466, 0.970802903175354]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model \n",
    "test_score = model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "epoch_nums = range(1,num_epochs+1)\n",
    "training_loss = history.history[\"loss\"]\n",
    "validation_loss = history.history[\"val_loss\"]\n",
    "plt.plot(epoch_nums, training_loss)\n",
    "plt.plot(epoch_nums, validation_loss)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['training', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습된 가중치와 편향 확인하기\n",
    "\n",
    "학습된 모델은 훈련 과정 중 optimizer에 의해 결정된 최종 가중치와 편향으로 구성된다. 네트워크 모델에 따라 각 레이어에 대해 다음 값을 예상해야 합니다.\n",
    "* 1번 레이어 : 10개의 출력 노드로 가는 4개의 입력 값이 있으므로 10 x 4 가중치와 10개의 바이어스 값이 있어야 합니다.\n",
    "* 2번 레이어 : 10개의 출력 노드로 가는 10개의 입력 값이 있으므로 10 x 10개의 가중치와 10개의 바이어스 값이 있어야 합니다.\n",
    "* 3번 레이어 : 3개의 출력 노드로 가는 10개의 입력 값이 있으므로 3 x 10개의 가중치와 3개의 바이어스 값이 있어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "Weights:\n",
      " [[-0.27236846 -0.3841947   0.03323996  0.08020484 -0.10909867  0.05681432\n",
      "  -0.19284694  0.84637016  0.35791102 -0.4905011 ]\n",
      " [ 0.27471453  0.21265197  0.08151417 -0.17707926 -0.10406601  0.80806166\n",
      "   0.347896   -0.05435276 -0.6077087  -0.5447268 ]\n",
      " [-0.28836262 -0.634329    0.2833844   0.34767175  0.23550075 -0.01211504\n",
      "   0.14559285 -0.7979028  -0.51647377  0.3296095 ]\n",
      " [-0.42851955 -0.24623463 -0.28597662 -0.5230521  -0.43773973  0.36980167\n",
      "  -0.07648169  0.23635657  0.75255555 -0.4691702 ]] \n",
      "Biases:\n",
      " [ 0.          0.         -0.01292545  0.          0.          0.20180525\n",
      " -0.19173317 -0.26139873 -0.3151644   0.        ]\n",
      "------------\n",
      "Weights:\n",
      " [[ 0.0607031  -0.30530828  0.39975524  0.3037489   0.15896738  0.03326017\n",
      "  -0.53190327  0.40915883 -0.03316814 -0.1240823 ]\n",
      " [ 0.42301047  0.14984506 -0.54566675  0.3919103  -0.4295466   0.50397205\n",
      "  -0.31616646  0.17803025 -0.41518384 -0.38429344]\n",
      " [ 0.5336163   0.37752342 -0.4694245   0.17206895 -0.04215616  0.5297911\n",
      "   0.43569055  0.28243896  0.26588058 -0.2233491 ]\n",
      " [-0.04491103  0.19579428 -0.26655364  0.17358297  0.3112036   0.53520477\n",
      "  -0.3109483  -0.5284722  -0.00098199 -0.44063687]\n",
      " [ 0.5135      0.39074183  0.39206952 -0.03048635  0.02663547  0.20555359\n",
      "   0.09307003  0.24590033 -0.49007446 -0.2917699 ]\n",
      " [ 0.5036509  -0.3901862   0.6040501   0.29417115 -0.26569188 -0.5313456\n",
      "   0.41422424 -0.15646715  0.00370714 -0.04586926]\n",
      " [ 0.26545775 -0.19090915  0.06543626 -0.30627972  0.12806404 -0.38203925\n",
      "  -0.21518534  0.4164291   0.26224646 -0.49726105]\n",
      " [-0.43842497 -0.21495155 -0.14274251 -0.46094683 -0.20800981  0.3025053\n",
      "  -0.01376947  0.40885046  0.27343398 -0.25861204]\n",
      " [-0.5077289  -0.4176368  -0.2463421  -0.49696004 -0.27225545 -0.38996994\n",
      "  -0.40834695  0.16559161 -0.2630665   0.2282074 ]\n",
      " [ 0.32320213 -0.30822456 -0.37115166  0.45703936 -0.35191107  0.24120325\n",
      "  -0.2000556   0.23292273 -0.33508268 -0.51532805]] \n",
      "Biases:\n",
      " [-0.03101544  0.          0.438202    0.          0.          0.\n",
      "  0.12232102 -0.2920643  -0.30329937 -0.0152769 ]\n",
      "------------\n",
      "Weights:\n",
      " [[-0.38350433  0.32607692 -0.04719266]\n",
      " [ 0.50995994 -0.12620813 -0.6595991 ]\n",
      " [ 0.53408676  0.02752906 -0.21620247]\n",
      " [ 0.54463303 -0.50025463  0.06109887]\n",
      " [ 0.26757038 -0.67376095 -0.18467396]\n",
      " [ 0.08888024 -0.2536324   0.20257705]\n",
      " [ 1.1712089  -1.5687631   0.64119864]\n",
      " [-0.4916294   0.385745    0.19551423]\n",
      " [-0.5256446  -0.3471337   0.68315786]\n",
      " [ 0.6409571  -0.6129823  -0.03113725]] \n",
      "Biases:\n",
      " [ 0.32178923  0.4605247  -0.49329963]\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()[0]\n",
    "    biases = layer.get_weights()[1]\n",
    "    print('------------\\nWeights:\\n',weights,'\\nBiases:\\n', biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 성능 평가하기\n",
    "\n",
    "그렇다면, 이 모델은 좋은 것일까요? 검증 데이터에서 보고된 정확도는 상당히 예측이 잘 된 것처럼 보이지만, 일반적으로 가능한 각 클래스의 예측을 좀 더 깊이 파고 비교하는 것이 유용합니다. 분류 모델의 성능을 시각화하는 일반적인 방법은 각 클래스에 대한 올바른 예측과 잘못된 예측의 crosstab을 보여 주는 *혼동 행렬(confusion matrix)* 을 만드는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tensorflow doesn't have a built-in confusion matrix metric, so we'll use SciKit-Learn\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "class_probabilities = model.predict(x_test)\n",
    "predictions = np.argmax(class_probabilities, axis=1)\n",
    "true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(penguin_classes))\n",
    "plt.xticks(tick_marks, penguin_classes, rotation=85)\n",
    "plt.yticks(tick_marks, penguin_classes)\n",
    "plt.xlabel(\"Actual Class\")\n",
    "plt.ylabel(\"Predicted Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "혼동 행렬은 각 클래스에 대해 부정확한 예측보다 더 많은 정확도가 있음을 강한 대각선 색상으로 표시해서 나타내야 한다.\n",
    "\n",
    "## 훈련된 모델 저장하기\n",
    "이제 상당히 정확하다고 생각되는 모델이 생겼으므로 나중에 사용할 수 있도록 교육된 가중치를 저장할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "modelFileName = 'models/penguin-classifier.h5'\n",
    "model.save(modelFileName)\n",
    "del model  # deletes the existing model variable\n",
    "print('model saved as', modelFileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습된 모델 사용하기\n",
    "\n",
    "우리가 새로운 펭귄을 관찰하게 되면, 우리는 학습된 모델을 사용하여 그 펭귄의 종을 예측할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "model = models.load_model(modelFileName)\n",
    "\n",
    "# CReate a new array of features\n",
    "x_new = np.array([[50.4,15.3,20,50]])\n",
    "print ('New sample: {}'.format(x_new))\n",
    "\n",
    "# Use the model to predict the class\n",
    "class_probabilities = model.predict(x_new)\n",
    "predictions = np.argmax(class_probabilities, axis=1)\n",
    "\n",
    "print(penguin_classes[predictions[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 더 배우기\n",
    "\n",
    "이 노트는 간단한 Tensorflow 예제를 사용하여 심층 신경망에 대한 기본 개념과 원리를 이해하도록 설계되었습니다. Tensorflow에 대한 자세한 내용은 <a href=\"https://www.tensorflow.org/\" target=\"_blank\">Tensorflow web site</a>를 참조하십시오."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
