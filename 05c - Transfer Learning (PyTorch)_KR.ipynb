{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전이 학습\n",
    "\n",
    "이미지 분류를 위한 CNN(Convolutional Neural Network)은 가장자리, 모서리 등과 같은 특징을 추출하는 여러 계층으로 구성됩니다. 그런 다음 최종 완전 연결 레이어를 사용하여 개체를 분류합니다. 다음과 같이 시각화 할 수 있습니다.\n",
    "\n",
    "<table>\n",
    "    <tr><td rowspan=2 style='border: 1px solid black;'>&#x21d2;</td><td style='border: 1px solid black;'>Convolutional Layer</td><td style='border: 1px solid black;'>Pooling Layer</td><td style='border: 1px solid black;'>Convolutional Layer</td><td style='border: 1px solid black;'>Pooling Layer</td><td style='border: 1px solid black;'>Fully Connected Layer</td><td rowspan=2 style='border: 1px solid black;'>&#x21d2;</td></tr>\n",
    "    <tr><td colspan=4 style='border: 1px solid black; text-align:center;'>Feature Extraction</td><td style='border: 1px solid black; text-align:center;'>Classification</td></tr>\n",
    "</table>\n",
    "\n",
    "*전이 학습*은 기존의 학습 된 모델을 가져 와서 특성 추출 계층을 재사용하여 최종 분류 계층을 사용자 지정 이미지로 훈련 된 완전 연결 계층으로 대체 할 수있는 기술 입니다. 이 기술을 사용하면 모델은 기본 모델 (액세스 권한이있는 것보다 더 큰 학습 데이터 세트를 기반으로 할 수 있음)에서 수행 된 특성 추출 학습을 통해 고유한 특정 객체 클래스 집합에 대한 분류 모델을 구축 할 수 있습니다.\n",
    "\n",
    "이게 무슨 도움이 될까요? 예를 들어보면 여러분이 프로 테니스 선수와 완전히 초보자를 데리고, 그들에게 라켓볼을 어떻게 하는지 가르치려고 노력한다고 가정해봅시다. 라켓볼에 관련된 기본 기술 중 많은 것들이 이미 학습되어 있기 때문에 프로 테니스 선수가 훈련하기 더 쉬울 것이라고 추측하는 것이 타당 합니다. 마찬가지로, 사전 교육된 CNN 모델은 가장자리 및 모서리와 같은 공통 객체의 특징을 식별하는 방법을 이미 배웠기 때문에 특정 객체 세트를 분류하기 위해 훈련하기가 더 쉬울 수 있습니다. 기본적으로, 사전 교육된 모델은 교육할 데이터가 제한된 경우에도 효과적인 분류기를 생성할 수 있는 좋은 방법이 될 수 있습니다.\n",
    "\n",
    "이 노트에서는 Pytorch를 사용하여 분류 모델에 대한 이전 학습을 구현하는 방법을 알아보겠습니다.\n",
    "\n",
    "## 라이브러리 설치 및 가져 오기\n",
    "\n",
    "사용할 PyTorch 라이브러리를 설치하고 가져옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch==1.7.1+cpu torchvision==0.8.2+cpu torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported - ready to use PyTorch 1.7.1+cpu\n"
     ]
    }
   ],
   "source": [
    "# Import PyTorch libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Other libraries we'll use\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Libraries imported - ready to use PyTorch\", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기본 모델 준비\n",
    "\n",
    "전이 학습을 사용하려면 훈련 된 피쳐 추출 레이어를 사용할 수 있는 기본 모델이 필요합니다. ***resnet*** 모델은 1000개의 객체 클래스의 많은 이미지를 포함하는 방대한 데이터 세트를 사용하여 사전 학습된 CNN 기반 이미지 분류기이므로 다운로드 하여 해당 레이어를 살펴보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /home/brfuser/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a8dca3451724c6b9291977590122f42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/83.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load the model (download if not already present)\n",
    "model = torchvision.models.resnet34(pretrained=True)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지 데이터 준비\n",
    "\n",
    "사전 훈련 된 모델에는 이미지 데이터에서 피쳐 추출 프로세스를 시작하는 convolution 레이어에서 시작하여 추출된 피쳐를 1000개의 클래스 레이블에 매핑하는 완전 연결 선형 레이어으로 끝나는 레이어 등, 여러 레이어들이 있습니다.\n",
    "\n",
    "특성 추출이 자체 이미지와 함께 작동하려면 예측 계층을 훈련하는데 사용하는 이미지 데이터에 피쳐 추출 레이어를 훈련하는 데 원래 사용 된 이미지와 동일한 수의 피쳐(픽셀 값)가 있는지 확인해야합니다. 모델은 크기를 명시적으로 제공하지 않지만 첫 번째 컨벌루션 레이어은 2x2의 stride을 가진 7x7 커널에 의해 적용되고 64 개의 특성 값이 생성되므로 원래 크기는 64x(7&div;2), 즉 224 여야합니다.\n",
    "\n",
    "PyTorch에는 데이터 로드 및 변환 기능이 포함되어 있습니다. 이를 사용하여 학습 데이터용 반복 로더(iterator loader)를 만들고 테스트 데이터용 두 번째 반복 로더(iterator loader)(학습된 모델의 유효성 검사에 사용)를 만듭니다. Loader는 원본 resnet CNN 모델을 훈련하는 데 사용된 형식과 일치하도록 이미지 데이터를 변환하고, 이미지 데이터를 *Tensor* (PyTorch에서 사용되는 핵심 데이터 구조)로 변환하고 정규화합니다.\n",
    "\n",
    "다음 셀을 실행하여 데이터 로더(DataLodaer)를 정의하고 이미지의 클래스를 나열하십시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class names: ['circle', 'square', 'triangle']\n"
     ]
    }
   ],
   "source": [
    "# Function to ingest data using training and test loaders\n",
    "def load_dataset(data_path):\n",
    "    \n",
    "    # Resize to 256 x 256, then center-crop to 224x224 (to match the resnet image size)\n",
    "    transformation = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    # Load all of the images, transforming them\n",
    "    full_dataset = torchvision.datasets.ImageFolder(\n",
    "        root=data_path,\n",
    "        transform=transformation\n",
    "    )\n",
    "    \n",
    "    # Split into training (70%) and testing (30%) datasets)\n",
    "    train_size = int(0.7 * len(full_dataset))\n",
    "    test_size = len(full_dataset) - train_size\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "    \n",
    "    # define a loader for the training data we can iterate through in 30-image batches\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=30,\n",
    "        num_workers=0,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # define a loader for the testing data we can iterate through in 30-image batches\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=30,\n",
    "        num_workers=0,\n",
    "        shuffle=False\n",
    "    )\n",
    "        \n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "# Now load the images from the shapes folder\n",
    "import os  \n",
    "data_path = 'data/shapes/'\n",
    "\n",
    "# Get the iterative dataloaders for test and training data\n",
    "train_loader, test_loader = load_dataset(data_path)\n",
    "\n",
    "# Get the class names\n",
    "classes = os.listdir(data_path)\n",
    "classes.sort()\n",
    "print('class names:', classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예측 레이어 만들기\n",
    "\n",
    "최종 **fc**(fully connected) 선형 레이어를 포함하여 전체 *resnet* 모델을 다운로드 했습니다. 이 fc 선형 계층은 512 개의 입력(추출 된 피쳐)을 사용하고 1000 개의 출력(원래 훈련 이미지 클래스를 기반으로 한 클래스 예측)을 생성합니다. 이 레이어를 동일한 수의 입력을 사용하는 레이어로 교체 해야하지만(추출 된 동일한 수의 특징을 사용할 수 있음) 각 이미지 클래스에 대한 예측을 생성합니다.\n",
    "\n",
    "또한 훈련 가중치를 유지하기 위해 피쳐 추출 레이어를 고정해야합니다. 그런 다음 이미지를 사용하여 모델을 학습할 때 최종 예측 레이어만 새로운 가중치와 편향값을 학습합니다. 피쳐 추출을 위해 사전 학습된 가중치는 동일하게 유지됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Set the existing feature extraction layers to read-only\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the prediction layer\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, len(classes))\n",
    "\n",
    "# Now print the full model, which will include the feature extraction layers of the base model and our prediction layer\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습\n",
    "\n",
    "CNN 레이어가 정의되었으므로 이미지 데이터를 사용하여 훈련 할 준비가되었습니다. 기본 resnet 모델의 특성 추출 레이어에 사용 된 가중치는 학습에 의해 변경되지 않으며 클래스에 매핑하는 최종 선형 계층(fc layer)만 훈련됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n",
      "Epoch: 1\n",
      "Training set [0/840 (0%)] Loss: 0.986712\n",
      "Training set [300/840 (36%)] Loss: 0.709709\n",
      "Training set [600/840 (71%)] Loss: 0.331256\n",
      "Training set: Average loss: 0.509090\n",
      "Validation set: Average loss: 0.290946, Accuracy: 355/360 (99%)\n",
      "\n",
      "Epoch: 2\n",
      "Training set [0/840 (0%)] Loss: 0.207845\n",
      "Training set [300/840 (36%)] Loss: 0.383816\n",
      "Training set [600/840 (71%)] Loss: 0.141192\n",
      "Training set: Average loss: 0.174805\n",
      "Validation set: Average loss: 0.105390, Accuracy: 360/360 (100%)\n",
      "\n",
      "Epoch: 3\n",
      "Training set [0/840 (0%)] Loss: 0.085142\n",
      "Training set [300/840 (36%)] Loss: 0.253075\n",
      "Training set [600/840 (71%)] Loss: 0.092507\n",
      "Training set: Average loss: 0.103070\n",
      "Validation set: Average loss: 0.070139, Accuracy: 360/360 (100%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    print(\"Epoch:\", epoch)\n",
    "    # Process the images in batches\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # Use the CPU or GPU as appropriate\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Reset the optimizer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Push the data forward through the model layers\n",
    "        output = model(data)\n",
    "        \n",
    "        # Get the loss\n",
    "        loss = loss_criteria(output, target)\n",
    "        \n",
    "        # Keep a running total\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print metrics for every 10 batches so we see some progress\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Training set [{}/{} ({:.0f}%)] Loss: {:.6f}'.format(\n",
    "                batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "    # return average loss for the epoch\n",
    "    avg_loss = train_loss / (batch_idx+1)\n",
    "    print('Training set: Average loss: {:.6f}'.format(avg_loss))\n",
    "    return avg_loss\n",
    "            \n",
    "            \n",
    "def test(model, device, test_loader):\n",
    "    # Switch the model to evaluation mode (so we don't backpropagate or drop)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        batch_count = 0\n",
    "        for data, target in test_loader:\n",
    "            batch_count += 1\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            # Get the predicted classes for this batch\n",
    "            output = model(data)\n",
    "            \n",
    "            # Calculate the loss for this batch\n",
    "            test_loss += loss_criteria(output, target).item()\n",
    "            \n",
    "            # Calculate the accuracy for this batch\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            correct += torch.sum(target==predicted).item()\n",
    "\n",
    "    # Calculate the average loss and total accuracy for this epoch\n",
    "    avg_loss = test_loss/batch_count\n",
    "    print('Validation set: Average loss: {:.6f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        avg_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    # return average loss for the epoch\n",
    "    return avg_loss\n",
    "    \n",
    "    \n",
    "# Now use the train and test functions to train and test the model    \n",
    "\n",
    "device = \"cpu\"\n",
    "if (torch.cuda.is_available()):\n",
    "    # if GPU available, use cuda (on a cpu, training will take a considerable length of time!)\n",
    "    device = \"cuda\"\n",
    "print('Training on', device)\n",
    "\n",
    "# Create an instance of the model class and allocate it to the device\n",
    "model = model.to(device)\n",
    "\n",
    "# Use an \"Adam\" optimizer to adjust weights\n",
    "# (see https://pytorch.org/docs/stable/optim.html#algorithms for details of supported algorithms)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Specify the loss criteria\n",
    "loss_criteria = nn.CrossEntropyLoss()\n",
    "\n",
    "# Track metrics in these arrays\n",
    "epoch_nums = []\n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "\n",
    "# Train over 3 epochs (in a real scenario, you'd likely use many more)\n",
    "epochs = 3\n",
    "for epoch in range(1, epochs + 1):\n",
    "        train_loss = train(model, device, train_loader, optimizer, epoch)\n",
    "        test_loss = test(model, device, test_loader)\n",
    "        epoch_nums.append(epoch)\n",
    "        training_loss.append(train_loss)\n",
    "        validation_loss.append(test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss(손실) 확인하기\n",
    "\n",
    "각 epoch에 대한 평균 훈련 및 검증 손실을 추적합니다. 그 이유는 모델이 학습됨에 따라 손실이 감소했는지 확인하고 *과적합* (검증 데이터의 손실이 평준화 되거나 증가하기 시작한 후에도 학습 데이터의 손실이 계속적으로 감소함을 나타냄)을 감지하기 위해 이를 시각화 하여 살펴봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(epoch_nums, training_loss)\n",
    "plt.plot(epoch_nums, validation_loss)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['training', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 성능 평가\n",
    "\n",
    "테스트 데이터를 기반으로 최종 정확도를 볼 수 있지만 일반적으로 성능 메트릭을 좀 더 자세히 살펴 보는게 좋습니다. 모델이 각 클래스를 얼마나 잘 예측하는지 확인하기 위해 confusion matrix(혼동 행렬)을 시각화 해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting predictions from test set...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Pytorch doesn't have a built-in confusion matrix metric, so we'll use SciKit-Learn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Set the model to evaluate mode\n",
    "model.eval()\n",
    "\n",
    "# Get predictions for the test data and convert to numpy arrays for use with SciKit-Learn\n",
    "print(\"Getting predictions from test set...\")\n",
    "truelabels = []\n",
    "predictions = []\n",
    "for data, target in test_loader:\n",
    "    for label in target.cpu().data.numpy():\n",
    "        truelabels.append(label)\n",
    "    for prediction in model.cpu()(data).data.numpy().argmax(1):\n",
    "        predictions.append(prediction) \n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(truelabels, predictions)\n",
    "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "plt.xlabel(\"Predicted Shape\")\n",
    "plt.ylabel(\"Actual Shape\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련된 모델 사용\n",
    "\n",
    "이제 모델을 학습 했으므로 이미지 클래스를 예측하는 데 사용할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "triangle\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to create a random image (of a square, circle, or triangle)\n",
    "def create_image (size, shape):\n",
    "    from random import randint\n",
    "    import numpy as np\n",
    "    from PIL import Image, ImageDraw\n",
    "    \n",
    "    xy1 = randint(10,40)\n",
    "    xy2 = randint(60,100)\n",
    "    col = (randint(0,200), randint(0,200), randint(0,200))\n",
    "\n",
    "    img = Image.new(\"RGB\", size, (255, 255, 255))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    if shape == 'circle':\n",
    "        draw.ellipse([(xy1,xy1), (xy2,xy2)], fill=col)\n",
    "    elif shape == 'triangle':\n",
    "        draw.polygon([(xy1,xy1), (xy2,xy2), (xy2,xy1)], fill=col)\n",
    "    else: # square\n",
    "        draw.rectangle([(xy1,xy1), (xy2,xy2)], fill=col)\n",
    "    del draw\n",
    "    \n",
    "    return img\n",
    "    \n",
    "# Function to predict the class of an image\n",
    "def predict_image(classifier, image):\n",
    "    import numpy\n",
    "    \n",
    "    # Set the classifer model to evaluation mode\n",
    "    classifier.eval()\n",
    "    \n",
    "    # Apply the same transformations as we did for the training images\n",
    "    transformation = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    # Preprocess the image\n",
    "    image_tensor = transformation(image).float()\n",
    "\n",
    "    # Add an extra batch dimension since pytorch treats all inputs as batches\n",
    "    image_tensor = image_tensor.unsqueeze_(0)\n",
    "\n",
    "    # Turn the input into a Variable\n",
    "    input_features = Variable(image_tensor)\n",
    "\n",
    "    # Predict the class of the image\n",
    "    output = classifier(input_features)\n",
    "    index = output.data.numpy().argmax()\n",
    "    return index\n",
    "\n",
    "\n",
    "# Now let's try it with a new image\n",
    "from random import randint\n",
    "from PIL import Image\n",
    "import os, shutil\n",
    "\n",
    "# Create a random test image\n",
    "shape = classes[randint(0, len(classes)-1)]\n",
    "img = create_image ((128,128), shape)\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(img)\n",
    "\n",
    "\n",
    "index = predict_image(model, img)\n",
    "print(classes[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn more\n",
    "\n",
    "* [PyTorch Documentation](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
